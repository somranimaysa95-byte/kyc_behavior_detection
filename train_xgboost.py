import pandas as pd
from xgboost import XGBClassifier, plot_importance
from sklearn.model_selection import train_test_split, StratifiedKFold
from sklearn.metrics import classification_report, confusion_matrix, ConfusionMatrixDisplay
import matplotlib.pyplot as plt
import joblib

print("ğŸš€ DÃ©marrage du script d'entraÃ®nement XGBoost...")

# === Je charge le dataset ===
print("ğŸ“¥ Chargement du fichier CSV...")
df = pd.read_csv("kyc_dataset_ready.csv")

# === Je vÃ©rifie que toutes les colonnes requises sont prÃ©sentes ===
print("ğŸ” VÃ©rification des colonnes requises...")
required_cols = [
    "duration_ms", "mouseClickCount", "scrollCount", "scrollDensity",
    "viewportChanges", "tabCount", "enterPressed", "deviceType_encoded",
    "fieldCount", "totalTimeSpent", "avgTimePerField", "totalFocusCount",
    "avgChangesPerField", "avgPastePerField", "avgDeletePerField",
    "fieldOrderDeviation", "stdTimePerField", "maxPasteCount", "pasteRatio",
    "deleteRatio", "label_target"
]
missing_cols = [col for col in required_cols if col not in df.columns]
if missing_cols:
    print("âŒ Colonnes manquantes :", missing_cols)
    raise ValueError(f"Colonnes manquantes dans le CSV : {missing_cols}")
else:
    print("âœ… Toutes les colonnes sont prÃ©sentes.")

# === Je sÃ©pare les features et le label ===
print("ğŸ“Š SÃ©paration des features et du label...")
X = df[required_cols[:-1]]
y = df["label_target"]

# === Je fais le split train/test ===
print("âœ‚ï¸ DÃ©coupage train/test...")
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)

# === J'entraÃ®ne le modÃ¨le XGBoost ===
print("ğŸ§  EntraÃ®nement du modÃ¨le XGBoost...")
clf = XGBClassifier(
    n_estimators=200,
    max_depth=6,
    learning_rate=0.1,
    subsample=0.8,
    colsample_bytree=0.8,
    random_state=42,
    eval_metric='mlogloss'
)
clf.fit(X_train, y_train)
print("âœ… ModÃ¨le entraÃ®nÃ© avec succÃ¨s.")

# === Je prÃ©dis sur le test set ===
print("ğŸ”® PrÃ©diction sur le test set...")
y_pred = clf.predict(X_test)

# === J'Ã©value le modÃ¨le ===
print("ğŸ“ˆ Ã‰valuation du modÃ¨le sur test set")
cm = confusion_matrix(y_test, y_pred)
print(cm)
print(classification_report(y_test, y_pred))

# === Je trace la matrice de confusion ===
print("ğŸ§© Affichage de la matrice de confusion...")
disp = ConfusionMatrixDisplay(confusion_matrix=cm, display_labels=["Normal", "Fraude"])
disp.plot(cmap="Blues")
plt.show()

# === Validation croisÃ©e manuelle avec analyse dÃ©taillÃ©e ===
print("\nğŸ” Validation croisÃ©e manuelle (5 folds) avec analyse dÃ©taillÃ©e...")
skf = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)
for i, (train_idx, test_idx) in enumerate(skf.split(X, y)):
    print(f"\nğŸ“‚ Fold {i+1}")
    X_train_fold, X_test_fold = X.iloc[train_idx], X.iloc[test_idx]
    y_train_fold, y_test_fold = y.iloc[train_idx], y.iloc[test_idx]

    clf_fold = XGBClassifier(
        n_estimators=200,
        max_depth=6,
        learning_rate=0.1,
        subsample=0.8,
        colsample_bytree=0.8,
        random_state=42,
        eval_metric='mlogloss'
    )
    clf_fold.fit(X_train_fold, y_train_fold)
    y_pred_fold = clf_fold.predict(X_test_fold)

    # === J'affiche les mÃ©triques ===
    print("Matrice de confusion :")
    print(confusion_matrix(y_test_fold, y_pred_fold))
    print("\nRapport de classification :")
    print(classification_report(y_test_fold, y_pred_fold))

    # === Je regarde la rÃ©partition des profils dans le fold ===
    print("RÃ©partition rÃ©elle des classes dans ce fold :", y_test_fold.value_counts())

    # === Je crÃ©e un tableau des sessions mal classÃ©es par profil ===
    errors = X_test_fold[y_test_fold != y_pred_fold]
    print(f"Nombre de sessions mal classÃ©es : {len(errors)}")
    if len(errors) > 0:
        print("Labels rÃ©els :", y_test_fold[y_test_fold != y_pred_fold].values)
        print("PrÃ©dictions :", y_pred_fold[y_test_fold != y_pred_fold])

    # === Je peux utiliser ces informations pour prÃ©parer ma fiche d'audit mÃ©tier ===
    # Justifier la robustesse de mon modÃ¨le
    # Expliquer comment je dÃ©tecte les fraudes stratÃ©giques

# === Je trace l'importance des features ===
print("ğŸ“Š Affichage de l'importance des features...")
plot_importance(clf)
plt.show()

# === Je sauvegarde le modÃ¨le ===
print("ğŸ’¾ Sauvegarde du modÃ¨le dans kyc_xgb_model.pkl...")
joblib.dump(clf, "kyc_xgb_model.pkl")
print("âœ… ModÃ¨le sauvegardÃ© avec succÃ¨s.")

print("ğŸ Script terminÃ©.")
